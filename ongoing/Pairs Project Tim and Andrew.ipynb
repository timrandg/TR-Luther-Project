{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice Lasso regularization technique in four steps on the given data set:\n",
    "\n",
    "1) Use the KFold function from sklearn to divide the data into 5 training/test sets.\n",
    "\n",
    "2) Tune the lambda parameter in the lasso model by looping over a grid of possible lambdas (sklearn: lasso)\n",
    "\n",
    "For each candidate lambda, loop over the 5 training/test sets.  \n",
    "On each training/test set run the lasso model on the training set and then compute and record the prediction error in the test set.  \n",
    "Finally total the prediction error for the 5 training/test sets.\n",
    "3) Set lambda to be the value that minimizes prediction error.\n",
    "\n",
    "4) Run the lasso model again with the optimal lambda determined in step 3. Which variables would you consider excluding on the basis of these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 2 & 3 Compatibility\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#from seaborn import plt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Lasso_practice_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.461197</td>\n",
       "      <td>-0.194500</td>\n",
       "      <td>0.488717</td>\n",
       "      <td>-2.090401</td>\n",
       "      <td>0.940031</td>\n",
       "      <td>2.016748</td>\n",
       "      <td>-1.273340</td>\n",
       "      <td>1.764350</td>\n",
       "      <td>-0.899677</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.267250</td>\n",
       "      <td>-2.134041</td>\n",
       "      <td>1.015223</td>\n",
       "      <td>-0.051486</td>\n",
       "      <td>-0.986937</td>\n",
       "      <td>0.769463</td>\n",
       "      <td>-0.118029</td>\n",
       "      <td>-0.305543</td>\n",
       "      <td>-0.835995</td>\n",
       "      <td>-0.928682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511853</td>\n",
       "      <td>1.780529</td>\n",
       "      <td>-1.577474</td>\n",
       "      <td>-1.974116</td>\n",
       "      <td>-0.517988</td>\n",
       "      <td>0.737993</td>\n",
       "      <td>-0.368043</td>\n",
       "      <td>0.427401</td>\n",
       "      <td>0.601782</td>\n",
       "      <td>1.937597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351190</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.274529</td>\n",
       "      <td>-0.586530</td>\n",
       "      <td>-0.273991</td>\n",
       "      <td>2.087001</td>\n",
       "      <td>-0.411038</td>\n",
       "      <td>-1.759816</td>\n",
       "      <td>0.271427</td>\n",
       "      <td>-0.800622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.747184</td>\n",
       "      <td>0.194354</td>\n",
       "      <td>-1.153263</td>\n",
       "      <td>-0.451070</td>\n",
       "      <td>-1.535572</td>\n",
       "      <td>0.059043</td>\n",
       "      <td>0.665234</td>\n",
       "      <td>0.846902</td>\n",
       "      <td>0.181277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479682</td>\n",
       "      <td>0.128315</td>\n",
       "      <td>-1.672293</td>\n",
       "      <td>-0.721750</td>\n",
       "      <td>0.582573</td>\n",
       "      <td>2.382982</td>\n",
       "      <td>-1.393823</td>\n",
       "      <td>-0.693469</td>\n",
       "      <td>-1.896798</td>\n",
       "      <td>0.935358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.534144</td>\n",
       "      <td>-0.412924</td>\n",
       "      <td>1.318229</td>\n",
       "      <td>1.545906</td>\n",
       "      <td>-0.354998</td>\n",
       "      <td>-1.684463</td>\n",
       "      <td>0.488385</td>\n",
       "      <td>-0.204598</td>\n",
       "      <td>-0.451744</td>\n",
       "      <td>0.359739</td>\n",
       "      <td>...</td>\n",
       "      <td>1.116924</td>\n",
       "      <td>1.081377</td>\n",
       "      <td>2.725351</td>\n",
       "      <td>0.174632</td>\n",
       "      <td>1.111195</td>\n",
       "      <td>0.097257</td>\n",
       "      <td>-1.084416</td>\n",
       "      <td>0.789806</td>\n",
       "      <td>-0.034149</td>\n",
       "      <td>-6.441607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150066</td>\n",
       "      <td>0.248695</td>\n",
       "      <td>0.144276</td>\n",
       "      <td>-0.774013</td>\n",
       "      <td>-0.918030</td>\n",
       "      <td>-0.134414</td>\n",
       "      <td>-0.176218</td>\n",
       "      <td>0.211906</td>\n",
       "      <td>1.576961</td>\n",
       "      <td>-0.286534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755798</td>\n",
       "      <td>-0.947922</td>\n",
       "      <td>1.544411</td>\n",
       "      <td>-1.238756</td>\n",
       "      <td>0.194689</td>\n",
       "      <td>1.660824</td>\n",
       "      <td>-0.443358</td>\n",
       "      <td>0.047590</td>\n",
       "      <td>1.199521</td>\n",
       "      <td>-4.805004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.014485  0.461197 -0.194500  0.488717 -2.090401  0.940031  2.016748   \n",
       "1  0.511853  1.780529 -1.577474 -1.974116 -0.517988  0.737993 -0.368043   \n",
       "2  0.004413  0.747184  0.194354 -1.153263 -0.451070 -1.535572  0.059043   \n",
       "3  0.534144 -0.412924  1.318229  1.545906 -0.354998 -1.684463  0.488385   \n",
       "4  0.150066  0.248695  0.144276 -0.774013 -0.918030 -0.134414 -0.176218   \n",
       "\n",
       "         x8        x9       x10    ...          x12       x13       x14  \\\n",
       "0 -1.273340  1.764350 -0.899677    ...    -1.267250 -2.134041  1.015223   \n",
       "1  0.427401  0.601782  1.937597    ...    -0.351190  0.009177  0.274529   \n",
       "2  0.665234  0.846902  0.181277    ...     0.479682  0.128315 -1.672293   \n",
       "3 -0.204598 -0.451744  0.359739    ...     1.116924  1.081377  2.725351   \n",
       "4  0.211906  1.576961 -0.286534    ...    -0.755798 -0.947922  1.544411   \n",
       "\n",
       "        x15       x16       x17       x18       x19       x20         y  \n",
       "0 -0.051486 -0.986937  0.769463 -0.118029 -0.305543 -0.835995 -0.928682  \n",
       "1 -0.586530 -0.273991  2.087001 -0.411038 -1.759816  0.271427 -0.800622  \n",
       "2 -0.721750  0.582573  2.382982 -1.393823 -0.693469 -1.896798  0.935358  \n",
       "3  0.174632  1.111195  0.097257 -1.084416  0.789806 -0.034149 -6.441607  \n",
       "4 -1.238756  0.194689  1.660824 -0.443358  0.047590  1.199521 -4.805004  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928977714238396"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we saw before, here is our baseline r^2 score\n",
    "lr=LinearRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100.0 => 0.9228572332654355\n",
      "-48.484848484848484 => 0.9276053958864197\n",
      "3.030303030303031 => 0.9289784318709495\n",
      "54.54545454545456 => 0.9276797934119564\n",
      "106.06060606060606 => 0.9242646870458194\n",
      "157.57575757575756 => 0.9191742357854416\n",
      "209.09090909090912 => 0.9127609783993008\n",
      "260.6060606060606 => 0.9053081068080436\n",
      "312.1212121212121 => 0.8970441218145643\n",
      "363.6363636363636 => 0.8881540989405874\n",
      "415.1515151515151 => 0.878788420237199\n",
      "466.66666666666663 => 0.8690695937833496\n",
      "518.1818181818182 => 0.859097617305909\n",
      "569.6969696969697 => 0.8489542243267902\n",
      "621.2121212121212 => 0.8387062660429515\n",
      "672.7272727272727 => 0.8284084200208073\n",
      "724.2424242424242 => 0.8181053710601267\n",
      "775.7575757575758 => 0.8078335756281186\n",
      "827.2727272727273 => 0.7976226958424509\n",
      "878.7878787878788 => 0.7874967698000638\n",
      "930.3030303030303 => 0.7774751704690823\n",
      "981.8181818181818 => 0.7675733942031033\n",
      "1033.3333333333333 => 0.7578037113419863\n",
      "1084.8484848484848 => 0.7481757047015273\n",
      "1136.3636363636365 => 0.7386967165610036\n",
      "1187.878787878788 => 0.7293722206865096\n",
      "1239.3939393939395 => 0.7202061327199629\n",
      "1290.909090909091 => 0.7112010697230856\n",
      "1342.4242424242425 => 0.7023585676441627\n",
      "1393.939393939394 => 0.6936792638596084\n",
      "1445.4545454545455 => 0.6851630506453832\n",
      "1496.969696969697 => 0.6768092043879063\n",
      "1548.4848484848485 => 0.6686164944982274\n",
      "1600.0 => 0.660583275306209\n",
      "1651.5151515151515 => 0.6527075636515092\n",
      "1703.030303030303 => 0.6449871044301878\n",
      "1754.5454545454545 => 0.637419425979993\n",
      "1806.060606060606 => 0.6300018868780966\n",
      "1857.5757575757575 => 0.6227317154697272\n",
      "1909.090909090909 => 0.6156060432347722\n",
      "1960.6060606060605 => 0.6086219329239393\n",
      "2012.121212121212 => 0.6017764022500234\n",
      "2063.6363636363635 => 0.5950664437979503\n",
      "2115.151515151515 => 0.5884890417153442\n",
      "2166.6666666666665 => 0.5820411856599075\n",
      "2218.181818181818 => 0.5757198824081085\n",
      "2269.6969696969695 => 0.5695221654692254\n",
      "2321.212121212121 => 0.5634451029977938\n",
      "2372.727272727273 => 0.557485804254402\n",
      "2424.2424242424245 => 0.5516414248282718\n",
      "2475.757575757576 => 0.5459091708040964\n",
      "2527.2727272727275 => 0.5402863020292931\n",
      "2578.787878787879 => 0.5347701346154308\n",
      "2630.3030303030305 => 0.5293580427885045\n",
      "2681.818181818182 => 0.5240474601864322\n",
      "2733.3333333333335 => 0.518835880688217\n",
      "2784.848484848485 => 0.5137208588473015\n",
      "2836.3636363636365 => 0.5087000099914185\n",
      "2887.878787878788 => 0.5037710100424808\n",
      "2939.3939393939395 => 0.4989315951025218\n",
      "2990.909090909091 => 0.49417956084523323\n",
      "3042.4242424242425 => 0.48951276174707037\n",
      "3093.939393939394 => 0.4849291101871021\n",
      "3145.4545454545455 => 0.48042657544065304\n",
      "3196.969696969697 => 0.4760031825882175\n",
      "3248.4848484848485 => 0.4716570113580455\n",
      "3300.0 => 0.4673861949181518\n",
      "3351.5151515151515 => 0.4631889186311987\n",
      "3403.030303030303 => 0.45906341878372536\n",
      "3454.5454545454545 => 0.45500798129947706\n",
      "3506.060606060606 => 0.4510209404451153\n",
      "3557.5757575757575 => 0.44710067753529825\n",
      "3609.090909090909 => 0.4432456196430258\n",
      "3660.6060606060605 => 0.43945423832017905\n",
      "3712.121212121212 => 0.43572504833236037\n",
      "3763.6363636363635 => 0.43205660641142773\n",
      "3815.151515151515 => 0.4284475100285017\n",
      "3866.6666666666665 => 0.4248963961896913\n",
      "3918.181818181818 => 0.4214019402563277\n",
      "3969.6969696969695 => 0.41796285479110573\n",
      "4021.212121212121 => 0.41457788843119003\n",
      "4072.727272727273 => 0.41124582478905836\n",
      "4124.242424242424 => 0.4079654813816055\n",
      "4175.757575757576 => 0.4047357085878155\n",
      "4227.272727272727 => 0.4015553886351435\n",
      "4278.787878787879 => 0.39842343461457985\n",
      "4330.30303030303 => 0.3953387895242544\n",
      "4381.818181818182 => 0.3923004253413255\n",
      "4433.333333333333 => 0.3893073421218064\n",
      "4484.848484848485 => 0.3863585671279176\n",
      "4536.363636363636 => 0.38345315398248025\n",
      "4587.878787878788 => 0.38059018184982585\n",
      "4639.393939393939 => 0.37776875464265547\n",
      "4690.909090909091 => 0.37498800025425283\n",
      "4742.424242424242 => 0.37224706981543\n",
      "4793.939393939394 => 0.3695451369755701\n",
      "4845.454545454546 => 0.36688139720712276\n",
      "4896.969696969697 => 0.3642550671328959\n",
      "4948.484848484849 => 0.36166538387549096\n",
      "5000.0 => 0.35911160442822676\n",
      "chosen alpha 3.030303030303031\n"
     ]
    }
   ],
   "source": [
    "# now\n",
    "# Is there an easier way to do train/test/validation and Ridge Regression altogether?  Of course there is!\n",
    "\n",
    "alphspace = np.linspace(-100,5000,100)\n",
    "#rcv = RidgeCV(cv=10,alphas=alphspace, store_cv_values=True)\n",
    "\n",
    "for a in alphspace:\n",
    "    #if you change the store_cv_values to True, and cv=None, it shows\n",
    "    #cv_values_ (its own cross validation values???!?!?!), which \n",
    "    #may be the issue...brain melting...\n",
    "    rcv = RidgeCV(cv=4,alphas=[a], store_cv_values=False)\n",
    "    rcv.fit(X_train, y_train)\n",
    "    sc = rcv.score(X_test, y_test)\n",
    "    #cv = rcv.cv_values_\n",
    "    print(f'{a} => {sc}')\n",
    "\n",
    "rcv = RidgeCV(cv=10,alphas=alphspace)\n",
    "rcv.fit(X_train, y_train)\n",
    "sc = rcv.score(X_test, y_test) \n",
    "print(f'chosen alpha {rcv.alpha_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.461197</td>\n",
       "      <td>-0.194500</td>\n",
       "      <td>0.488717</td>\n",
       "      <td>-2.090401</td>\n",
       "      <td>0.940031</td>\n",
       "      <td>2.016748</td>\n",
       "      <td>-1.273340</td>\n",
       "      <td>1.764350</td>\n",
       "      <td>-0.899677</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.267250</td>\n",
       "      <td>-2.134041</td>\n",
       "      <td>1.015223</td>\n",
       "      <td>-0.051486</td>\n",
       "      <td>-0.986937</td>\n",
       "      <td>0.769463</td>\n",
       "      <td>-0.118029</td>\n",
       "      <td>-0.305543</td>\n",
       "      <td>-0.835995</td>\n",
       "      <td>-0.928682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511853</td>\n",
       "      <td>1.780529</td>\n",
       "      <td>-1.577474</td>\n",
       "      <td>-1.974116</td>\n",
       "      <td>-0.517988</td>\n",
       "      <td>0.737993</td>\n",
       "      <td>-0.368043</td>\n",
       "      <td>0.427401</td>\n",
       "      <td>0.601782</td>\n",
       "      <td>1.937597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351190</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.274529</td>\n",
       "      <td>-0.586530</td>\n",
       "      <td>-0.273991</td>\n",
       "      <td>2.087001</td>\n",
       "      <td>-0.411038</td>\n",
       "      <td>-1.759816</td>\n",
       "      <td>0.271427</td>\n",
       "      <td>-0.800622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.747184</td>\n",
       "      <td>0.194354</td>\n",
       "      <td>-1.153263</td>\n",
       "      <td>-0.451070</td>\n",
       "      <td>-1.535572</td>\n",
       "      <td>0.059043</td>\n",
       "      <td>0.665234</td>\n",
       "      <td>0.846902</td>\n",
       "      <td>0.181277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479682</td>\n",
       "      <td>0.128315</td>\n",
       "      <td>-1.672293</td>\n",
       "      <td>-0.721750</td>\n",
       "      <td>0.582573</td>\n",
       "      <td>2.382982</td>\n",
       "      <td>-1.393823</td>\n",
       "      <td>-0.693469</td>\n",
       "      <td>-1.896798</td>\n",
       "      <td>0.935358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.534144</td>\n",
       "      <td>-0.412924</td>\n",
       "      <td>1.318229</td>\n",
       "      <td>1.545906</td>\n",
       "      <td>-0.354998</td>\n",
       "      <td>-1.684463</td>\n",
       "      <td>0.488385</td>\n",
       "      <td>-0.204598</td>\n",
       "      <td>-0.451744</td>\n",
       "      <td>0.359739</td>\n",
       "      <td>...</td>\n",
       "      <td>1.116924</td>\n",
       "      <td>1.081377</td>\n",
       "      <td>2.725351</td>\n",
       "      <td>0.174632</td>\n",
       "      <td>1.111195</td>\n",
       "      <td>0.097257</td>\n",
       "      <td>-1.084416</td>\n",
       "      <td>0.789806</td>\n",
       "      <td>-0.034149</td>\n",
       "      <td>-6.441607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150066</td>\n",
       "      <td>0.248695</td>\n",
       "      <td>0.144276</td>\n",
       "      <td>-0.774013</td>\n",
       "      <td>-0.918030</td>\n",
       "      <td>-0.134414</td>\n",
       "      <td>-0.176218</td>\n",
       "      <td>0.211906</td>\n",
       "      <td>1.576961</td>\n",
       "      <td>-0.286534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755798</td>\n",
       "      <td>-0.947922</td>\n",
       "      <td>1.544411</td>\n",
       "      <td>-1.238756</td>\n",
       "      <td>0.194689</td>\n",
       "      <td>1.660824</td>\n",
       "      <td>-0.443358</td>\n",
       "      <td>0.047590</td>\n",
       "      <td>1.199521</td>\n",
       "      <td>-4.805004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.014485  0.461197 -0.194500  0.488717 -2.090401  0.940031  2.016748   \n",
       "1  0.511853  1.780529 -1.577474 -1.974116 -0.517988  0.737993 -0.368043   \n",
       "2  0.004413  0.747184  0.194354 -1.153263 -0.451070 -1.535572  0.059043   \n",
       "3  0.534144 -0.412924  1.318229  1.545906 -0.354998 -1.684463  0.488385   \n",
       "4  0.150066  0.248695  0.144276 -0.774013 -0.918030 -0.134414 -0.176218   \n",
       "\n",
       "         x8        x9       x10    ...          x12       x13       x14  \\\n",
       "0 -1.273340  1.764350 -0.899677    ...    -1.267250 -2.134041  1.015223   \n",
       "1  0.427401  0.601782  1.937597    ...    -0.351190  0.009177  0.274529   \n",
       "2  0.665234  0.846902  0.181277    ...     0.479682  0.128315 -1.672293   \n",
       "3 -0.204598 -0.451744  0.359739    ...     1.116924  1.081377  2.725351   \n",
       "4  0.211906  1.576961 -0.286534    ...    -0.755798 -0.947922  1.544411   \n",
       "\n",
       "        x15       x16       x17       x18       x19       x20         y  \n",
       "0 -0.051486 -0.986937  0.769463 -0.118029 -0.305543 -0.835995 -0.928682  \n",
       "1 -0.586530 -0.273991  2.087001 -0.411038 -1.759816  0.271427 -0.800622  \n",
       "2 -0.721750  0.582573  2.382982 -1.393823 -0.693469 -1.896798  0.935358  \n",
       "3  0.174632  1.111195  0.097257 -1.084416  0.789806 -0.034149 -6.441607  \n",
       "4 -1.238756  0.194689  1.660824 -0.443358  0.047590  1.199521 -4.805004  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 => 0.9218473639750295\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "####  LASSO  ########\n",
    "#####################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\n",
    "\n",
    "# now\n",
    "# Is there an easier way to do train/test/validation and Ridge Regression altogether?  Of course there is!\n",
    "\n",
    "alphspace = np.linspace(0,5000,100)\n",
    "#rcv = RidgeCV(cv=10,alphas=alphspace, store_cv_values=True)\n",
    "\n",
    "#for a in alphspace:\n",
    "lcv = LassoCV(cv=5,alphas=alphspace)\n",
    "lcv.fit(X_train, y_train)\n",
    "sc = lcv.score(X_test, y_test)\n",
    "print(f'{lcv.alpha_} => {sc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/loaner/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('x6', 1.8673679609887857),\n",
       " ('x16', 1.0194837512983888),\n",
       " ('x10', 0.17128214371472256),\n",
       " ('x3', -0.139270767566622),\n",
       " ('x9', -0.21814320001686738),\n",
       " ('x20', -0.37112882723379725),\n",
       " ('x2', -1.821279729687301),\n",
       " ('x14', -2.2255043058268584)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 2 & 3 Compatibility\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#from seaborn import plt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('Lasso_practice_data.csv')\n",
    "y_trans = data.y\n",
    "X_trans = data.drop(['y'], 1)\n",
    "\n",
    "kf = KFold(n=len(data), n_folds=5, shuffle=True)\n",
    "\n",
    "all_scores=[]\n",
    "#alphas=[ 1e-4,0.3e-2,0.7e-2, 1e-2,1.1e-1,1.3e-2, 1e-1,1]\n",
    "alphas = np.linspace(1e-5,0,120)\n",
    "\n",
    "for train, test in kf:\n",
    "    x_train=X_trans.iloc[train]\n",
    "    y_train=y_trans.iloc[train]\n",
    "    x_test=X_trans.iloc[test]\n",
    "    y_test=y_trans.iloc[test]\n",
    "    mse_score=[]\n",
    "    al = []\n",
    "    for a in alphas:\n",
    "        est=Lasso(alpha=a)\n",
    "        est.fit(x_train,y_train)\n",
    "        mse=np.mean((y_test-est.predict(x_test))**2)\n",
    "        mse_score.append(mse)\n",
    "        al.append(a)\n",
    "    all_scores.append(mse_score)\n",
    "#for e in all_scores :\n",
    "#    print(e)\n",
    "\n",
    "for list in all_scores:\n",
    "    plt.scatter(al, mse_score)\n",
    "    plt.xlim(alphas[0], alphas[-1])\n",
    "    #plt.ylim(min(all_scores), max(all_scores))\n",
    "plt.show()\n",
    "\n",
    "alpha = 1e-2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\n",
    "\n",
    "est=Lasso(alpha=a)\n",
    "est.fit(X_train,y_train)\n",
    "zipped = zip(X_trans.columns, est.coef_)\n",
    "features = sorted(zipped, key=lambda t:t[1], reverse=True)\n",
    "[x for x in features if abs(x[1]) > 0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
